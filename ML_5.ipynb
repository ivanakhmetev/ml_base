{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TEc9cV7IGsMg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28     # Размер изображения в точках\n",
        "hidden_size = 1500      # Количество нейронов в скрытом слое\n",
        "num_classes = 10       # Количество распознающихся классов (10 цифр)\n",
        "n_epochs = 4           # Количество эпох\n",
        "batch_size = 20         # Размер мини-пакета входных данных\n",
        "lr = 0.01              # Скорость обучения"
      ],
      "metadata": {
        "id": "lTM5E58LGube"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "mnist_trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_testset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "print(len(mnist_trainset))\n",
        "print(len(mnist_testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if-R4lEjG0MF",
        "outputId": "16e5c0e5-b179-4da9-85d7-bf0be51c9570"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 114264818.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 77205668.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30490256.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13784753.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_trainset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True) # загрузчик обучающих данных\n",
        "test_loader = torch.utils.data.DataLoader(dataset=mnist_testset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False) # загрузчик тестовых данных"
      ],
      "metadata": {
        "id": "V5ze91uJG1tu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# импортируем нужные библиотеки\n",
        "import torch\n",
        "import numpy as np # всегда пригодится :)\n",
        "from torch.nn import Linear, Sigmoid\n",
        "\n",
        "# инициализируем девайс\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# добавляем типовую функцию \"шаг обучения\"\n",
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    def train_step(x, y):\n",
        "        model.train()\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        return loss.item()\n",
        "    return train_step"
      ],
      "metadata": {
        "id": "RriFbS12G3st"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim, nn\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size * 2),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.03),\n",
        "    nn.Linear(hidden_size * 2, num_classes))\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        loss = train_step(images, labels)\n",
        "    print(epoch)\n",
        "\n",
        "# print(model.state_dict())\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqXChVJDG5r0",
        "outputId": "238a32f1-7fd5-4354-f695-426e482e95df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0.07590556889772415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Точность: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqSiIOEbG8XU",
        "outputId": "6e2d5375-c2a2-4322-d3c1-9fb95ade2003"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность: 96.43 %\n"
          ]
        }
      ]
    }
  ]
}